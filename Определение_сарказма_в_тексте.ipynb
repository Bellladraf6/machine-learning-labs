{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1HztKl2b4i2vKgbsB8GFkTnQmOnFrKzf8",
      "authorship_tag": "ABX9TyOpm/8iteil16L+wIFellpX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bellladraf6/machine-learning-labs/blob/main/%D0%9E%D0%BF%D1%80%D0%B5%D0%B4%D0%B5%D0%BB%D0%B5%D0%BD%D0%B8%D0%B5_%D1%81%D0%B0%D1%80%D0%BA%D0%B0%D0%B7%D0%BC%D0%B0_%D0%B2_%D1%82%D0%B5%D0%BA%D1%81%D1%82%D0%B5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BwdfuR_SKP-6",
        "outputId": "f5069b4c-867e-412f-cbe2-f930cf1caaec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Первая строка токенизированного текста: [  308 15115   679  3337  2298    48   382  2576 15116     6  2577  8434\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0]\n",
            "Форма всего набора данных: (26709, 40)\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Шаг 1: Загрузка данных\n",
        "datastore = []\n",
        "with open('Sarcasm_Headlines_Dataset.json', 'r') as f:\n",
        "    for line in f:\n",
        "        datastore.append(json.loads(line))\n",
        "\n",
        "# Шаг 2: Извлечение заголовков и меток\n",
        "sentences = [item['headline'] for item in datastore]\n",
        "labels = [item['is_sarcastic'] for item in datastore]\n",
        "\n",
        "# Шаг 3: Токенизация текста\n",
        "tokenizer = Tokenizer(oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "# Шаг 4: Преобразование текста в последовательности\n",
        "sequences = tokenizer.texts_to_sequences(sentences)\n",
        "\n",
        "# Шаг 5: Паддинг последовательностей\n",
        "padded = pad_sequences(sequences, padding='post')\n",
        "\n",
        "# Вывод первой строки и формы набора данных\n",
        "print(\"Первая строка токенизированного текста:\", padded[0])\n",
        "print(\"Форма всего набора данных:\", padded.shape)\n",
        "\n"
      ]
    }
  ]
}